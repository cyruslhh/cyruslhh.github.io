<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> CS180 Project 6 | Cyrus Hung </title> <meta name="author" content="Cyrus Hung"> <meta name="description" content="Neural Radiance Fields"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cyruslhh.github.io/projects/CS180_project_6/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Cyrus</span> Hung </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Me </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">CS180 </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/projects/CS180_project_1/">Project 1</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/CS180_project_2/">Project 2</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/CS180_project_3/">Project 3</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/CS180_project_4/">Project 4</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/CS180_project_5/">Project 5</a> <a class="dropdown-item " href="/projects/CS180_project_6/">Project 6</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">CS180 Project 6</h1> <p class="post-description">Neural Radiance Fields</p> </header> <article> <h1 id="part-1-2d-neural-field">Part 1: 2D Neural Field</h1> <p>Before we use a Neural Radiance Field to represent a 3D space, we can use a NeRF on a 2D example. Essentially, we’ll make a model that takes in a pixel coordinate {u, v} and output a color {r, g, b} in 2D space. We’ll use one image and train our model on it, then sample every single coordinate possible to get the resulting image. Of course, there’s really no need to do this as the image itself gives you the RGB value provided the coordinate, but this serves as a warmup.</p> <p>We’ll use the following architecture and try it the following two images.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.0.1-480.webp 480w,/assets/img/CS180/Project_6/1.0.1-800.webp 800w,/assets/img/CS180/Project_6/1.0.1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.0.1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Provided Image </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.0.2-480.webp 480w,/assets/img/CS180/Project_6/1.0.2-800.webp 800w,/assets/img/CS180/Project_6/1.0.2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.0.2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Model Architecture </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.0.3-480.webp 480w,/assets/img/CS180/Project_6/1.0.3-800.webp 800w,/assets/img/CS180/Project_6/1.0.3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.0.3.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Custom Image </div> </div> </div> <p>The PE refers to a Sinusoidal Encoding, applying sin and cos functions to the input coordinates to expand its dimensionality. Here, we use an L of 10, so we’ll expand our input from 2D (u, v) to 42.</p> \[PE(x) = \{x, \sin(2^0 \pi x), \cos(2^0 \pi x), \sin(2^1 \pi x), \cos(2^1 \pi x), \ldots, \sin(2^{L-1} \pi x), \cos(2^{L-1} \pi x)\}\] <p>Using a simple dataloader (that just randomly gets coordinates and provides the corresponding pixel color), the class architecture and running on the Adam Optimizer with a 1e-2 learning rate, MSE Loss, and 10k batch size for 2000 iterations, we get the results below for the provided fox image, along with the PSNR curve:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.1.1-480.webp 480w,/assets/img/CS180/Project_6/1.1.1-800.webp 800w,/assets/img/CS180/Project_6/1.1.1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.1.1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Fox over iterations ([1, 50, 100, 600, 1000, 2000]) </div> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.1.2-480.webp 480w,/assets/img/CS180/Project_6/1.1.2-800.webp 800w,/assets/img/CS180/Project_6/1.1.2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.1.2.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> PSNR over iterations </div> </div> </div> <p>I also tried running some hyperparameter training on the provided image. Here’s the result of decreasing the number of layers from 4 to 3, and decreasing L from 10 to 6.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.2.1-480.webp 480w,/assets/img/CS180/Project_6/1.2.1-800.webp 800w,/assets/img/CS180/Project_6/1.2.1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.2.1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Fox over iterations ([1, 50, 100, 600, 1000, 2000]), small model </div> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.2.2-480.webp 480w,/assets/img/CS180/Project_6/1.2.2-800.webp 800w,/assets/img/CS180/Project_6/1.2.2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.2.2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> PSNR over iterations, small model </div> </div> </div> <p>Surprisingly the results were still very good, which perhaps just shows how the task isn’t very complex and can be handled with a less sophisticated model.</p> <p>Then, let’s try increasing the layers from 4 to 5, and L from 10 to 12 to make a big model.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.3.1-480.webp 480w,/assets/img/CS180/Project_6/1.3.1-800.webp 800w,/assets/img/CS180/Project_6/1.3.1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.3.1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Fox over iterations ([1, 50, 100, 600, 1000, 2000]), large model </div> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.3.2-480.webp 480w,/assets/img/CS180/Project_6/1.3.2-800.webp 800w,/assets/img/CS180/Project_6/1.3.2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.3.2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> PSNR over iterations, large model </div> </div> </div> <p>Tragedy. Interestingly we achieve a higher PSNR but the model clearly overfits.</p> <p>Let’s now try using the smaller model, which we found to be effective, on the picture of my cat:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.4.1-480.webp 480w,/assets/img/CS180/Project_6/1.4.1-800.webp 800w,/assets/img/CS180/Project_6/1.4.1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.4.1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Cat over iterations ([1, 50, 100, 600, 1000, 2000]), small model </div> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/1.4.2-480.webp 480w,/assets/img/CS180/Project_6/1.4.2-800.webp 800w,/assets/img/CS180/Project_6/1.4.2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/1.4.2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Cat over iterations, small model </div> </div> </div> <p>Surprisingy the smaller model is quite successful.</p> <h1 id="part-2-3d-neural-field">Part 2: 3D Neural Field</h1> <h2 id="part-21-functions">Part 2.1: Functions</h2> <p>Onto the real deal! As explained in class. We’ll get a bunch of images of a lego bulldozer from different angles, the camera coordinates, and other information (camera-to-world transformation matrices), train a powerful NeRF model on the information, and try to render the image from novel views given our information using some validation and test camera information that was provided.</p> <p>First, we’ll implement three algorithms needed to train and sample: Camera to World Conversion, Pixel to Camera Coordinate Conversion, and Pixel to Ray conversion. All of these are taken from the course website and implement in pytorch.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> $$ \begin{align} \begin{bmatrix} x_c \\ y_c \\ z_c \\ 1 \end{bmatrix} = \begin{bmatrix} \mathbf{R}_{3\times3} &amp; \mathbf{t} \\ \mathbf{0}_{1\times3} &amp; 1 \end{bmatrix} \begin{bmatrix} x_w \\ y_w \\ z_w \\ 1 \end{bmatrix} \end{align} $$ <div class="caption"> Camera to World Coordinate Conversion </div> </div> <div class="col-sm mt-3 mt-md-0"> $$ \begin{align} \mathbf{K} = \begin{bmatrix} f_x &amp; 0 &amp; o_x \\ 0 &amp; f_y &amp; o_y \\ 0 &amp; 0 &amp; 1 \end{bmatrix} \end{align} $$ $$ \begin{align} s \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = \mathbf{K} \begin{bmatrix} x_c \\ y_c \\ z_c \end{bmatrix} \end{align} $$ <div class="caption"> Pixel to Camera Coordinate Conversion </div> </div> <div class="col-sm mt-3 mt-md-0"> $$ \begin{align} \mathbf{r}_o = -\mathbf{R}_{3\times3}^{-1}\mathbf{t} \end{align} $$ $$ \begin{align} \mathbf{r}_d = \frac{\mathbf{X_w} - \mathbf{r}_o}{||\mathbf{X_w} - \mathbf{r}_o||_2} \end{align} $$ <div class="caption"> Pixel To Ray </div> </div> </div> <p>To get the W2C matrix for extracting R and T in Pixel To Ray, I simply used the inverse of C2W that was passed in.</p> <h2 id="part-22-dataloader">Part 2.2: DataLoader</h2> <p>Next, we’ll need to make a DataLoader that can be used to provide our model with information. The goal is for the dataloader to provide two sampling functions: sample_rays(num_rays) and sample_along_rays(rays_o, rays_d, perturb). As the DataLoader will only be loaded in once while sample_rays will be run thousands of times, I optimized the dataloader such that all possible rays and pixels are pre-computed, and sample_rays can then simply index into the vast number of rays and pixels as data.</p> <p>The Dataset takes in the training images, an intrinsic matrix K, and each image’s camera2world matrix.</p> <ol> <li>For each image, we’ll get every single possible coordinate and its corresponding pixel value (uv), and store it.</li> <li>Shift the coordinates by 0.5, so that the ray points at the middle of the pixel rather than a corner.</li> <li>Use the pixel_to_ray formula above to get a list of all ray origins and ray directions for all pixels.</li> </ol> <p>Then, to sample we’ll just simply randomly select without replacement a list of indices from our list of all pixel values, and use the corresponding indices to get the uv, ray_o, and ray_d.</p> <p>For the sample_along_rays function I followed the staff formula and set n_samples to 64, near=2, far=6, and t_width=0.02. We also introduce perturbations so that the points aren’t evenly spaced for each ray to prevent overfitting.</p> <h2 id="part-23-visualization">Part 2.3: Visualization</h2> <p>Plugging in the staff code to ensure my code thus far has been working well, we can see a visualization of 100 randomly selected rays amongst all our cameras, as well as the perturbations we introduced in sample_along_rays. During one training loop, we’ll use 10,000 rays instead. I also included 100 rays only for 1 image on the top right corner, provided by the staff visualization code.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.3.1-480.webp 480w,/assets/img/CS180/Project_6/2.3.1-800.webp 800w,/assets/img/CS180/Project_6/2.3.1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.3.1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 100 rays with num_samples=64 and perturbations </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.3.2-480.webp 480w,/assets/img/CS180/Project_6/2.3.2-800.webp 800w,/assets/img/CS180/Project_6/2.3.2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.3.2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 100 rays with num_samples=64, top right of camera 1 </div> </div> </div> <h2 id="part-24-neural-radiance-field">Part 2.4: Neural Radiance Field</h2> <p>For the model, I used the staff provided architecture:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.4.1-480.webp 480w,/assets/img/CS180/Project_6/2.4.1-800.webp 800w,/assets/img/CS180/Project_6/2.4.1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.4.1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>With Hyperparameters/parameters:</p> <ul> <li>L_x=10, L_d=4, num_hidden=256</li> <li>Adam optimizer, lr=8e-4</li> <li>ExponentialLR scheduler, gamma=0.9999</li> <li>5000 iterations (later increased to 30,000)</li> <li>10k batch_size</li> <li>64 num_samples in sample_along_rays, with t_width=2.0</li> </ul> <h2 id="part-25-volume-rendering">Part 2.5: Volume Rendering</h2> <p>The model outputs a density and RGB. To actually get the final color of a pixel, we’ll need to combine the rgb/densities we collected from the model at each point using the staff formula, which I implemented using pytorch.:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> $$ \begin{align} C(\mathbf{r})=\int_{t_n}^{t_f} T(t) \sigma(\mathbf{r}(t)) \mathbf{c}(\mathbf{r}(t), \mathbf{d}) d t, \text { where } T(t)=\exp \left(-\int_{t_n}^t \sigma(\mathbf{r}(s)) d s\right) \end{align} $$ <div class="caption"> Real formula </div> </div> <div class="col-sm mt-3 mt-md-0"> $$ \begin{align} \hat{C}(\mathbf{r})=\sum_{i=1}^N T_i\left(1-\exp \left(-\sigma_i \delta_i\right)\right) \mathbf{c}_i, \text { where } T_i=\exp \left(-\sum_{j=1}^{i-1} \sigma_j \delta_j\right) \end{align} $$ <div class="caption"> Our discrete approximation </div> </div> </div> <h2 id="results">Results:</h2> <p>Here’s many samples from various iterations for validation camera 1, with the real image on the left.</p> <div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.1-480.webp 480w,/assets/img/CS180/Project_6/2.5.1-800.webp 800w,/assets/img/CS180/Project_6/2.5.1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Samples from model (expected | iter=100, 200, 400, 1000, 2000, 5000) </div> </div> </div> <p>Here are the corresponding PSNR curve comparing with 6 images from the validation set (which we’ll check every 100 iterations). I also included the corresponding training psnr (which is collected every iteration).</p> <div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.2-480.webp 480w,/assets/img/CS180/Project_6/2.5.2-800.webp 800w,/assets/img/CS180/Project_6/2.5.2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> training and validation PNSR </div> </div> </div> <p>We can clearly see that it plateaus around 5000 iterations. Let’s now sample from the test cameras at different iterations and see how the model evolves, by creating a gif for all the camera angles provided in the test_c2ws:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.3-480.webp 480w,/assets/img/CS180/Project_6/2.5.3-800.webp 800w,/assets/img/CS180/Project_6/2.5.3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.3.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 100 gradient steps </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.4-480.webp 480w,/assets/img/CS180/Project_6/2.5.4-800.webp 800w,/assets/img/CS180/Project_6/2.5.4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.4.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 200 gradient steps </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.5-480.webp 480w,/assets/img/CS180/Project_6/2.5.5-800.webp 800w,/assets/img/CS180/Project_6/2.5.5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.5.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 400 gradient steps </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.6-480.webp 480w,/assets/img/CS180/Project_6/2.5.6-800.webp 800w,/assets/img/CS180/Project_6/2.5.6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.6.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 1000 gradient steps </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.7-480.webp 480w,/assets/img/CS180/Project_6/2.5.7-800.webp 800w,/assets/img/CS180/Project_6/2.5.7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.7.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 2000 gradient steps </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.8-480.webp 480w,/assets/img/CS180/Project_6/2.5.8-800.webp 800w,/assets/img/CS180/Project_6/2.5.8-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.8.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 5000 gradient steps </div> </div> </div> <p>And just for fun, I decided to train for about 3 hours, up to 30000 iterations. Here are the results:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.9-480.webp 480w,/assets/img/CS180/Project_6/2.5.9-800.webp 800w,/assets/img/CS180/Project_6/2.5.9-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.9.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 10000 gradient steps </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.10-480.webp 480w,/assets/img/CS180/Project_6/2.5.10-800.webp 800w,/assets/img/CS180/Project_6/2.5.10-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.10.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 15000 gradient steps </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.11-480.webp 480w,/assets/img/CS180/Project_6/2.5.11-800.webp 800w,/assets/img/CS180/Project_6/2.5.11-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.11.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 20000 gradient steps </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.12-480.webp 480w,/assets/img/CS180/Project_6/2.5.12-800.webp 800w,/assets/img/CS180/Project_6/2.5.12-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.12.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> 30000 gradient steps </div> </div> </div> <p>As we can see, the differences aren’t that significant. Although it’s pretty interesting it didn’t overfit and cause strange things to start happening.</p> <h2 id="bell-and-whistle">Bell and Whistle</h2> <p>By simply modifying our volrend function, we can add background color. Basically, we want to render and return the background color in the case that our ray “hits” nothing, which currently gives us black. By examining our equation above, we can think of T as a weight for the color provided by the model. By adding a (1-T) * bg_color term, we can inject background color:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="height: 25%;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CS180/Project_6/2.5.13-480.webp 480w,/assets/img/CS180/Project_6/2.5.13-800.webp 800w,/assets/img/CS180/Project_6/2.5.13-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/CS180/Project_6/2.5.13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="camera man" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> background color injected </div> </div> </div> <h1 id="conclusions">Conclusions</h1> <p>Overall this was by far the hardest project in the semester. The provided staff code, explanations, and formulas were extremely useful in the implementation, and the sense of triumph as I got the first gif is indescribable.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Cyrus Hung. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-me",title:"Me",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"dropdown-project-1",title:"Project 1",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-project-2",title:"Project 2",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-project-3",title:"Project 3",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-project-4",title:"Project 4",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-project-5",title:"Project 5",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-project-6",title:"Project 6",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-cs180-project-1",title:"CS180 Project 1",description:"Colorizing the Prokudin-Gorskii photo collection",section:"Projects",handler:()=>{window.location.href="/projects/CS180_project_1/"}},{id:"projects-cs180-project-2",title:"CS180 Project 2",description:"Fun with Filters and Frequencies",section:"Projects",handler:()=>{window.location.href="/projects/CS180_project_2/"}},{id:"projects-cs180-project-3",title:"CS180 Project 3",description:"Face Morphing and Modelling a Photo Collection",section:"Projects",handler:()=>{window.location.href="/projects/CS180_project_3/"}},{id:"projects-cs180-project-4",title:"CS180 Project 4",description:"Image Warp + Mosaic",section:"Projects",handler:()=>{window.location.href="/projects/CS180_project_4/"}},{id:"projects-cs180-project-5",title:"CS180 Project 5",description:"Fun Wth Diffusion Models!",section:"Projects",handler:()=>{window.location.href="/projects/CS180_project_5/"}},{id:"projects-cs180-project-6",title:"CS180 Project 6",description:"Neural Radiance Fields",section:"Projects",handler:()=>{window.location.href="/projects/CS180_project_6/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6C%68%63%79%72%75%73%68%75%6E%67@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>